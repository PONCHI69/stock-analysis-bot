import yfinance as yf
import pandas as pd
import requests
import os
from bs4 import BeautifulSoup
import time

DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

def get_potential_stocks():
    print("æ­£åœ¨åŸ·è¡Œç²¾æº–åŒ–ã€é•·ç·š 5 å¹´å€å¢ã€æƒæ...")
    try:
        # è»Œé“ä¸€ï¼šæŠ“å–ç†±é–€æˆäº¤è‚¡ (å‰ 150 æª”)
        url = "https://tw.stock.yahoo.com/ranking/volume?type=tse"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        df = pd.read_html(res.text)[0]
        
        candidate_data = []
        for _, row in df.head(150).iterrows():
            parts = str(row['è‚¡ç¥¨åç¨±']).split(' ')
            if len(parts) >= 2:
                candidate_data.append({"symbol": f"{parts[0]}.TW", "name": parts[1], "id": parts[0]})

        # è»Œé“äºŒï¼šä¸»å‹•åŠ å…¥é•·ç·šæ ¸å¿ƒè¿½è¹¤åå–® (å¯è‡ªç”±å¢æ¸›)
        core_list = [
            {"symbol": "2330.TW", "name": "å°ç©é›»", "id": "2330"},
            {"symbol": "2317.TW", "name": "é´»æµ·", "id": "2317"},
            {"symbol": "2454.TW", "name": "è¯ç™¼ç§‘", "id": "2454"},
            {"symbol": "2308.TW", "name": "å°é”é›»", "id": "2308"}
        ]
        candidate_data.extend(core_list)

        symbols = list(set([item['symbol'] for item in candidate_data]))
        data = yf.download(symbols, period="5y", group_by='ticker', progress=False)
        
        ultra_long_picks = []
        for item in candidate_data:
            s = item['symbol']
            if s not in data or data[s].empty: continue
            df_hist = data[s].dropna()
            if len(df_hist) < 400: continue

            curr_price = df_hist['Close'].iloc[-1]
            five_yr_high = df_hist['Close'].max()
            five_yr_low = df_hist['Close'].min()
            ma200 = df_hist['Close'].rolling(window=200).mean().iloc[-1]
            
            # --- å¹³è¡¡å¾Œçš„é•·ç·šç­–ç•¥ ---
            # A. è·é›¢é«˜é»ä»æœ‰ 20% ç©ºé–“å³å¯ (é©æ‡‰ç›®å‰çš„å¼·å‹¢ç›¤)
            is_deep_value = curr_price < (five_yr_high * 0.8)
            # B. è¶¨å‹¢é–€æª»ï¼šåªè¦è‚¡åƒ¹æ¥è¿‘æˆ–é«˜æ–¼å¹´ç·š
            is_near_ma200 = curr_price > (ma200 * 0.95)
            # C. åº•éƒ¨ä¿è­·ï¼šç›¸å°æ–¼ 5 å¹´ä½é»æ¼²å¹…ä¸è¶…é 150%
            is_not_sky_high = curr_price < (five_yr_low * 2.5)
            
            if is_deep_value and is_near_ma200 and is_not_sky_high:
                ultra_long_picks.append({
                    "id": item['id'],
                    "name": item['name'],
                    "price": round(curr_price, 2),
                    "dist_to_high": round(((five_yr_high - curr_price) / curr_price) * 100, 1)
                })
        return ultra_long_picks
    except Exception as e:
        print(f"æƒæå‡ºéŒ¯: {e}")
        return []

# get_stock_news èˆ‡ run_analysis å‡½æ•¸ç¶­æŒä¸è®Š
def get_stock_news(cname):
    try:
        url = f"https://news.google.com/rss/search?q={cname}+ç ”ç™¼+OR+å¸‚ä½”+OR+å…¨çƒ+when:7d&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
        res = requests.get(url)
        soup = BeautifulSoup(res.content, features="xml")
        items = soup.find_all('item')[:2]
        return "\n".join([f"â€¢ {i.title.text}" for i in items]) if items else "â€¢ æš«ç„¡é•·ç·šäº®é»å ±å°"
    except:
        return "â€¢ æ–°èè®€å–å¤±æ•—"

def run_analysis():
    potentials = get_potential_stocks()
    if not potentials:
        msg = "ğŸ’¡ ç›¤å‹¢ä½éšåé«˜ï¼Œæš«ç„¡ç¬¦åˆé•·ç·šä½ˆå±€æ¢ä»¶ä¹‹æ¨™çš„ã€‚"
    else:
        msg = "ğŸ›ï¸ **ã€å„ªåŒ–ç‰ˆé•·ç·šä½ˆå±€ã€‘5 å¹´ 3 å€æ½›åŠ›è‚¡æƒæ**\n"
        msg += "----------------------------\n"
        for s in potentials:
            news = get_stock_news(s['name'])
            msg += f"ğŸ¯ **{s['name']} ({s['id']})**\n"
            msg += f"ç¾åƒ¹ï¼š{s['price']} | è· 5 å¹´é«˜é»å°šæœ‰ï¼š{s['dist_to_high']}% ç©ºé–“\n"
            msg += f"ã€é•·ç·šå‹•èƒ½åˆ†æã€‘\n{news}\n"
            msg += f"ğŸ”— [æŸ¥çœ‹åœ–è¡¨](https://tw.stock.yahoo.com/quote/{s['id']})\n"
            msg += "----------------------------\n"
    if DISCORD_WEBHOOK_URL:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})

if __name__ == "__main__":
    run_analysis()
