import yfinance as yf
import pandas as pd
import requests
import os
from bs4 import BeautifulSoup
import time

# --- åƒæ•¸è¨­å®š ---
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

def get_potential_stocks():
    print("æ­£åœ¨åŸ·è¡Œã€é•·ç·šå¼·å‹¢å›æª”ã€æ½›åŠ›è‚¡æƒæ...")
    try:
        # 1. æŠ“å–æˆäº¤é‡æ’è¡Œ (å‰ 150 å) ä»¥ç¢ºä¿æµå‹•æ€§
        url = "https://tw.stock.yahoo.com/ranking/volume?type=tse"
        res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
        df = pd.read_html(res.text)[0]
        
        candidate_data = []
        for _, row in df.head(150).iterrows():
            parts = str(row['è‚¡ç¥¨åç¨±']).split(' ')
            if len(parts) >= 2:
                candidate_data.append({"symbol": f"{parts[0]}.TW", "name": parts[1], "id": parts[0]})

        symbols = [item['symbol'] for item in candidate_data]
        # æŠ“å– 2 å¹´è³‡æ–™åˆ†æè¶¨å‹¢å³å¯ï¼Œä¸é ˆå¼·æ±‚ 5 å¹´ä»¥ç¶­æŒæ•ˆç‡
        data = yf.download(symbols, period="2y", group_by='ticker', progress=False)
        
        potential_picks = []
        for item in candidate_data:
            s = item['symbol']
            if s not in data or data[s].empty: continue
            df_hist = data[s].dropna()
            if len(df_hist) < 200: continue

            curr_price = df_hist['Close'].iloc[-1]
            prev_price = df_hist['Close'].iloc[-2]
            
            # è¨ˆç®—å‡ç·šæŒ‡æ¨™
            ma200_all = df_hist['Close'].rolling(window=200).mean()
            curr_ma200 = ma200_all.iloc[-1]
            prev_ma200_month = ma200_all.iloc[-20] # ä¸€å€‹æœˆå‰çš„å¹´ç·š

            # --- 2026 å¯¦æˆ°ç­–ç•¥ï¼šå¼·å‹¢å›æ¸¬è²·é» ---
            # A. é•·ç·šè¶¨å‹¢å‘ä¸Šï¼šå¹´ç·šæœ¬èº«å¿…é ˆæ˜¯å¾€ä¸Šèµ°çš„ (æœˆå¢å¹… > 1%)
            is_uptrend = curr_ma200 > (prev_ma200_month * 1.01)
            
            # B. ç²¾æº–è²·é»ï¼šè‚¡åƒ¹æ­£å¥½å›æ¸¬åˆ°å¹´ç·šæ”¯æ’ (é›¢å¹´ç·šä¸Šä¸‹ 5% å…§)
            is_at_support = (curr_price > curr_ma200 * 0.95) and (curr_price < curr_ma200 * 1.05)
            
            # C. ä¹–é›¢é™åˆ¶ï¼šæ’é™¤è¿‘æœŸå™´ç™¼éé ­çš„ (è·é›¢ 1 å¹´é«˜é»ä¸è¶…é 30%)
            year_high = df_hist['Close'].iloc[-250:].max()
            is_not_overheated = curr_price < (year_high * 0.95)

            if is_uptrend and is_at_support and is_not_overheated:
                potential_picks.append({
                    "id": item['id'],
                    "name": item['name'],
                    "price": round(curr_price, 2),
                    "change": round(((curr_price - prev_price) / prev_price) * 100, 2),
                    "reason": "ğŸ›¡ï¸ å¼·å‹¢è‚¡å›æ¸¬å¹´ç·š (é•·ç·šæ”¯æ’é»)"
                })
        return potential_picks
    except Exception as e:
        print(f"æƒæå¤±æ•—: {e}")
        return []

def get_stock_news(cname):
    try:
        url = f"https://news.google.com/rss/search?q={cname}+è¨‚å–®+OR+ç‡Ÿæ”¶+when:7d&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
        res = requests.get(url)
        soup = BeautifulSoup(res.content, features="xml")
        items = soup.find_all('item')[:2]
        return "\n".join([f"â€¢ {i.title.text}" for i in items]) if items else "â€¢ æš«ç„¡è¿‘æœŸç”¢æ¥­é—œéµå ±å°"
    except:
        return "â€¢ æ–°èè®€å–å¤±æ•—"

def run_analysis():
    picks = get_potential_stocks()
    if not picks:
        msg = "ğŸ’¡ ç›®å‰ç›¤å‹¢ä½éšé«˜ï¼Œå¤šæ•¸å¼·å‹¢è‚¡å°šæœªå›æ¸¬æ”¯æ’ï¼Œå»ºè­°ä¿ç•™ç¾é‡‘ç­‰å¾…å›èª¿ã€‚"
    else:
        msg = "ğŸ¯ **ã€é•·ç·šä½ˆå±€è¨ˆç•«ã€‘ç¸¾å„ªå¼·å‹¢è‚¡å›æ¸¬æƒæ**\n"
        msg += "----------------------------\n"
        for s in picks:
            news = get_stock_news(s['name'])
            msg += f"ğŸ”¥ **{s['name']} ({s['id']})**\n"
            msg += f"ç¾åƒ¹ï¼š{s['price']} ({s['change']:+}%)\n"
            msg += f"è¨Šè™Ÿï¼š{s['reason']}\n"
            msg += f"ã€è¿‘æœŸé—œéµè¨Šæ¯ã€‘\n{news}\n"
            msg += f"ğŸ”— [æŸ¥çœ‹é•·ç·šåœ–è¡¨](https://tw.stock.yahoo.com/quote/{s['id']})\n"
            msg += "----------------------------\n"
    if DISCORD_WEBHOOK_URL:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})

if __name__ == "__main__":
    run_analysis()
