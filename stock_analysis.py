import yfinance as yf
import pandas as pd
import requests
import os
from bs4 import BeautifulSoup
import time

# --- åƒæ•¸è¨­å®š ---
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")
# è¨­ç½® headers é¿å…è¢«ç¶²ç«™é˜»æ“‹
HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36'}

def get_potential_stocks():
    print("æ­£åœ¨æƒæå…·å‚™ã€5 å¹´ 3 å€ã€æ½›åŠ›çš„è¶…é•·ç·šæ¨™çš„...")
    try:
        # 1. æ“´å¤§æƒæç¯„åœè‡³ 100 æª”
        url = "https://tw.stock.yahoo.com"
        res = requests.get(url, headers=HEADERS)
        df = pd.read_html(res.text)[0]
        
        candidate_data = []
        for _, row in df.head(100).iterrows():
            raw_text = str(row['è‚¡ç¥¨åç¨±']).split(' ')
            if len(raw_text) >= 2:
                candidate_data.append({"symbol": f"{raw_text[0]}.TW", "name": raw_text[1], "id": raw_text[0]})

        symbols = [item['symbol'] for item in candidate_data]
        # 2. æ™‚é–“ç¶­åº¦ï¼šæŠ“å– 5 å¹´è³‡æ–™ä»¥åˆ†æè¶…é•·ç·šä½éš
        data = yf.download(symbols, period="5y", group_by='ticker', progress=False)
        
        ultra_long_picks = []
        for item in candidate_data:
            s = item['symbol']
            
            # --- ç²å–åŸºæœ¬é¢è³‡æ–™ ---
            # é€™è£¡éœ€è¦å–®ç¨ Ticker å‘¼å« info (é€Ÿåº¦è¼ƒæ…¢ï¼Œä½†é•·ç·šç­–ç•¥é »ç‡ä½å¯æ¥å—)
            try:
                stock_info = yf.Ticker(s).info
                total_debt = stock_info.get('totalDebt', 0)
                total_cash = stock_info.get('totalCash', 0)
                # æ¢ä»¶ D: è²¡å‹™ç©©å¥æ€§ - ç¾é‡‘å¤šæ–¼è² å‚µ
                is_financially_sound = total_cash > total_debt if total_debt > 0 else True 
            except:
                is_financially_sound = False # å¦‚æœæŠ“ä¸åˆ°è³‡æ–™å°±è·³é

            if s not in data or data[s].empty or not is_financially_sound: continue
            
            df_hist = data[s].dropna()
            # ç¢ºä¿æœ‰è¶³å¤ çš„æ­·å²æ•¸æ“š (5å¹´ç´„ 1200 äº¤æ˜“æ—¥)
            if len(df_hist) < 500: continue

            curr_price = df_hist['Close'].iloc[-1]
            five_year_high = df_hist['Close'].max()
            five_year_low = df_hist['Close'].min()
            
            # è¨ˆç®— 200 æ—¥å¹´ç·š
            ma200 = df_hist['Close'].rolling(window=200).mean().iloc[-1]
            
            # --- 5 å¹´ 3 å€ç¯©é¸é‚è¼¯ ---
            # A: ä½éšç›¸å°ä½ - è‚¡åƒ¹è·é›¢ 5 å¹´é«˜é»ä»æœ‰ 40% ä»¥ä¸Šç©ºé–“ (èª¿æ•´ç‚º 40%)
            is_deep_value = curr_price < (five_year_high * 0.6) 
            
            # B: åº•éƒ¨æ”¯æ’ - è‚¡åƒ¹ç›®å‰é«˜æ–¼ 5 å¹´æœ€ä½é»ï¼Œä½†é‚„æ²’æš´æ¼² (è·é›¢ä½é»æ¼²å¹…å°æ–¼ 50%)
            is_above_floor = curr_price > five_year_low and curr_price < (five_year_low * 1.5)
            
            # C: è¶¨å‹¢è½‰æ­£ - è‚¡åƒ¹ç«™ä¸Šå¹´ç·š (MA200)
            is_trend_ready = curr_price > ma200
            
            
            if is_deep_value and is_above_floor and is_trend_ready:
                ultra_long_picks.append({
                    "id": item['id'],
                    "name": item['name'],
                    "price": round(curr_price, 2),
                    "dist_to_high": round(((five_year_high - curr_price) / curr_price) * 100, 1),
                    "reason": "ğŸ›ï¸ è¶…é•·ç·šåƒ¹å€¼å€ (5å¹´ä½ä½)"
                })
        
        return ultra_long_picks

    except Exception as e:
        print(f"æƒæå¤±æ•—: {e}")
        return []

def get_stock_news(cname):
    try:
        # åŠ å…¥é•·ç·šæˆé•·é—œéµå­—ï¼šç ”ç™¼ã€å¸‚ä½”ã€å°ˆåˆ©
        url = f"https://news.google.com{cname}+ç ”ç™¼+OR+å¸‚ä½”+OR+å…¨çƒ+when:7d&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
        res = requests.get(url)
        soup = BeautifulSoup(res.content, features="xml")
        items = soup.find_all('item')[:2]
        return "\n".join() if items else "â€¢ æš«ç„¡é•·ç·šç”¢æ¥­å¸ƒå±€è¨Šæ¯"
    except:
        return "â€¢ æ–°èè®€å–å¤±æ•—"

def run_analysis():
    potentials = get_potential_stocks()
    
    if not potentials:
        msg = "ğŸ’¡ ç›®å‰æš«æœªç™¼ç¾ç¬¦åˆã€è¶…é•·ç·š 5 å¹´å€å¢ã€æ½›åŠ›ä¹‹æ¨™çš„ã€‚"
    else:
        msg = "ğŸ›ï¸ **ã€è¶…é•·ç·šä½ˆå±€è¨ˆç•«ã€‘5 å¹´ 3 å€æ½›åŠ›è‚¡æƒæ**\n"
        msg += "----------------------------\n"
        for s in potentials:
            news = get_stock_news(s['name'])
            yahoo_link = f"https://tw.stock.yahoo.com{s['id']}"
            msg += f"ğŸ¯ **{s['name']} ({s['id']})**\n"
            msg += f"ç¾åƒ¹ï¼š{s['price']} | è· 5 å¹´é«˜é»ä»æœ‰ï¼š{s['dist_to_high']}% ç©ºé–“\n"
            msg += f"ç‹€æ…‹ï¼šâœ… æ­·å²ä½ä½ç¯‰åº•å®Œæˆ\n"
            msg += f"{news}\n"
            msg += f"ğŸ”— [æŸ¥çœ‹ 5 å¹´å¤§é€±æœŸåœ–è¡¨]({yahoo_link})\n"
            msg += "----------------------------\n"

    if DISCORD_WEBHOOK_URL:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})
    else:
        print(msg)

if __name__ == "__main__":
    run_analysis()
