import yfinance as yf
import pandas as pd
import requests
import os
from bs4 import BeautifulSoup
import time

# --- åƒæ•¸è¨­å®š ---
DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK")

def get_potential_stocks():
    print("æ­£åœ¨å¾ç†±é–€æ± æƒæå…·å‚™ã€5 å¹´ 3 å€ã€æ½›åŠ›çš„æ¨™çš„...")
    try:
        # æ”¹æŠ“æˆäº¤é‡å‰ 150 åï¼Œé€™åŒ…å«äº†æ‰€æœ‰å…·å‚™æµå‹•æ€§çš„ä¸­å°å‹æˆé•·è‚¡
        url = "https://tw.stock.yahoo.com/ranking/volume?type=tse"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers)
        df = pd.read_html(res.text)[0]
        
        candidate_data = []
        for _, row in df.head(150).iterrows(): # æ“´å¤§æ± å­
            raw_text = str(row['è‚¡ç¥¨åç¨±']).split(' ')
            if len(raw_text) >= 2:
                candidate_data.append({"symbol": f"{raw_text[0]}.TW", "name": raw_text[1], "id": raw_text[0]})

        symbols = [item['symbol'] for item in candidate_data]
        # æ‰¹æ¬¡ä¸‹è¼‰æ•¸æ“šï¼Œæå‡é€Ÿåº¦
        data = yf.download(symbols, period="5y", group_by='ticker', progress=False)
        
        ultra_long_picks = []
        for item in candidate_data:
            s = item['symbol']
            if s not in data or data[s].empty: continue
            df_hist = data[s].dropna()
            if len(df_hist) < 400: continue # ç¢ºä¿æœ‰è¶³å¤ æ•¸æ“š

            curr_price = df_hist['Close'].iloc[-1]
            five_yr_high = df_hist['Close'].max()
            five_yr_low = df_hist['Close'].min()
            ma200 = df_hist['Close'].rolling(window=200).mean().iloc[-1]
            
            # --- 5 å¹´ 3 å€ç­–ç•¥å„ªåŒ– ---
            # A. ä½éšç©ºé–“ï¼šè·é›¢ 5 å¹´é«˜é»ä»æœ‰ 35% ä»¥ä¸Šç©ºé–“ (ä½ä½éš)
            is_deep_value = curr_price < (five_yr_high * 0.65)
            # B. åº•éƒ¨ä¿è­·ï¼šç›¸å°æ–¼ 5 å¹´ä½é»ï¼Œæ¼²å¹…ä¸è¶…é 100% (é¿å…å·²æ¼²éé ­)
            is_not_sky_high = curr_price < (five_yr_low * 2.0)
            # C. è¶¨å‹¢è½‰å¼·ï¼šè‚¡åƒ¹åœ¨å¹´ç·š (MA200) çš„ 10% ç¯„åœå…§ (ä»£è¡¨ç¯‰åº•å®Œæˆæº–å‚™è½‰å¼·)
            is_near_ma200 = curr_price > (ma200 * 0.9)
            
            if is_deep_value and is_not_sky_high and is_near_ma200:
                ultra_long_picks.append({
                    "id": item['id'],
                    "name": item['name'],
                    "price": round(curr_price, 2),
                    "dist_to_high": round(((five_yr_high - curr_price) / curr_price) * 100, 1)
                })
        return ultra_long_picks
    except Exception as e:
        print(f"æƒæå¤±æ•—: {e}")
        return []

def get_stock_news(cname):
    try:
        url = f"https://news.google.com/rss/search?q={cname}+ç ”ç™¼+OR+å¸‚ä½”+OR+å…¨çƒ+when:7d&hl=zh-TW&gl=TW&ceid=TW:zh-tw"
        res = requests.get(url)
        soup = BeautifulSoup(res.content, features="xml")
        items = soup.find_all('item')[:2]
        # ä¿®æ­£åŸæœ¬ "\n".join() çš„ç©ºåƒæ•¸éŒ¯èª¤
        return "\n".join([f"â€¢ {i.title.text}" for i in items]) if items else "â€¢ æš«ç„¡é•·ç·šç”¢æ¥­å¸ƒå±€è¨Šæ¯"
    except:
        return "â€¢ æ–°èè®€å–å¤±æ•—"

def run_analysis():
    potentials = get_potential_stocks()
    if not potentials:
        msg = "ğŸ’¡ ç›¤å‹¢ä½éšåé«˜ï¼Œç›®å‰æš«ç„¡ç¬¦åˆã€è¶…é•·ç·š 5 å¹´å€å¢ã€ä½ä½éšæ¨™çš„ã€‚"
    else:
        msg = "ğŸ›ï¸ **ã€é•·ç·šåƒ¹å€¼ä½ˆå±€ã€‘5 å¹´ 3 å€æ½›åŠ›è‚¡æƒæ**\n"
        msg += "----------------------------\n"
        for s in potentials:
            news = get_stock_news(s['name'])
            yahoo_link = f"https://tw.stock.yahoo.com/quote/{s['id']}" # ä¿®æ­£é€£çµ
            msg += f"ğŸ¯ **{s['name']} ({s['id']})**\n"
            msg += f"ç¾åƒ¹ï¼š{s['price']} | è· 5 å¹´é«˜é»ä»æœ‰ï¼š{s['dist_to_high']}% ç©ºé–“\n"
            msg += f"ç‹€æ…‹ï¼šâœ… æ­·å²ä½ä½ç¯‰åº•å®Œæˆ\n"
            msg += f"{news}\n"
            msg += f"ğŸ”— [æŸ¥çœ‹ 5 å¹´å¤§é€±æœŸåœ–è¡¨]({yahoo_link})\n"
            msg += "----------------------------\n"
    if DISCORD_WEBHOOK_URL:
        requests.post(DISCORD_WEBHOOK_URL, json={"content": msg})

if __name__ == "__main__":
    run_analysis()
